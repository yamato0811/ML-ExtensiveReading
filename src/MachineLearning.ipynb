{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モジュール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polyglot.text import Text   #形態素解析\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re  #正規表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文章の整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\\\n",
    "Dorothy lived in the midst of the great Kansas prairies, with Uncle\n",
    "Henry, who was a farmer, and Aunt Em, who was the farmer’s wife. Their\n",
    "house was small, for the lumber to build it had to be carried by wagon\n",
    "many miles. There were four walls, a floor and a roof, which made one\n",
    "room; and this room contained a rusty looking cookstove, a cupboard for\n",
    "the dishes, a table, three or four chairs, and the beds. Uncle Henry\n",
    "and Aunt Em had a big bed in one corner, and Dorothy a little bed in\n",
    "another corner. There was no garret at all, and no cellar—except a\n",
    "small hole dug in the ground, called a cyclone cellar, where the family\n",
    "could go in case one of those great whirlwinds arose, mighty enough to\n",
    "crush any building in its path. It was reached by a trap door in the\n",
    "middle of the floor, from which a ladder led down into the small, dark\n",
    "hole.\n",
    "\n",
    "When Dorothy stood in the doorway and looked around, she could see\n",
    "nothing but the great gray prairie on every side. Not a tree nor a\n",
    "house broke the broad sweep of flat country that reached to the edge of\n",
    "the sky in all directions. The sun had baked the plowed land into a\n",
    "gray mass, with little cracks running through it. Even the grass was\n",
    "not green, for the sun had burned the tops of the long blades until\n",
    "they were the same gray color to be seen everywhere. Once the house had\n",
    "been painted, but the sun blistered the paint and the rains washed it\n",
    "away, and now the house was as dull and gray as everything else.\n",
    "\n",
    "When Aunt Em came there to live she was a young, pretty wife. The sun\n",
    "and wind had changed her, too. They had taken the sparkle from her eyes\n",
    "and left them a sober gray; they had taken the red from her cheeks and\n",
    "lips, and they were gray also. She was thin and gaunt, and never smiled\n",
    "now. When Dorothy, who was an orphan, first came to her, Aunt Em had\n",
    "been so startled by the child’s laughter that she would scream and\n",
    "press her hand upon her heart whenever Dorothy’s merry voice reached\n",
    "her ears; and she still looked at the little girl with wonder that she\n",
    "could find anything to laugh at.\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 形態素解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 品詞タグを数値に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PROPN', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ',\n",
       "       'PROPN', 'NOUN', 'PUNCT', 'ADP', 'NOUN', 'PROPN', 'PUNCT', 'PRON',\n",
       "       'VERB', 'DET', 'NOUN', 'PUNCT', 'CONJ', 'PROPN', 'PROPN', 'PUNCT',\n",
       "       'PRON', 'VERB', 'DET', 'NUM', 'NOUN', 'PUNCT', 'PRON', 'NOUN',\n",
       "       'VERB', 'ADJ', 'PUNCT', 'ADP', 'DET', 'NOUN', 'PART', 'VERB',\n",
       "       'PRON', 'VERB', 'PART', 'AUX', 'VERB', 'ADP', 'NOUN', 'ADJ',\n",
       "       'NOUN', 'PUNCT', 'DET', 'VERB', 'NUM', 'NOUN', 'PUNCT', 'DET',\n",
       "       'NOUN', 'CONJ', 'DET', 'NOUN', 'PUNCT', 'DET', 'VERB', 'NUM',\n",
       "       'NOUN', 'PUNCT', 'CONJ', 'DET', 'NOUN', 'VERB', 'DET', 'ADJ',\n",
       "       'NOUN', 'NUM', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN',\n",
       "       'PUNCT', 'DET', 'NOUN', 'PUNCT', 'NUM', 'CONJ', 'NUM', 'NOUN',\n",
       "       'PUNCT', 'CONJ', 'DET', 'NOUN', 'PUNCT', 'NOUN', 'PROPN', 'CONJ',\n",
       "       'NOUN', 'PROPN', 'VERB', 'DET', 'ADJ', 'NOUN', 'ADP', 'NUM',\n",
       "       'NOUN', 'PUNCT', 'CONJ', 'PROPN', 'DET', 'ADJ', 'NOUN', 'ADP',\n",
       "       'DET', 'NOUN', 'PUNCT', 'DET', 'VERB', 'DET', 'PROPN', 'ADV',\n",
       "       'PROPN', 'PUNCT', 'CONJ', 'DET', 'NOUN', 'PUNCT', 'VERB', 'DET',\n",
       "       'ADJ', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'PUNCT', 'VERB',\n",
       "       'DET', 'NOUN', 'NOUN', 'PUNCT', 'ADV', 'DET', 'NOUN', 'AUX',\n",
       "       'VERB', 'ADP', 'NOUN', 'NUM', 'ADP', 'DET', 'ADJ', 'NUM', 'VERB',\n",
       "       'PUNCT', 'ADJ', 'ADV', 'PART', 'VERB', 'DET', 'NOUN', 'ADP',\n",
       "       'PRON', 'NOUN', 'PUNCT', 'PRON', 'AUX', 'VERB', 'ADP', 'DET',\n",
       "       'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN',\n",
       "       'PUNCT', 'ADP', 'DET', 'DET', 'NOUN', 'VERB', 'ADV', 'ADP', 'DET',\n",
       "       'ADJ', 'PUNCT', 'ADJ', 'NOUN', 'PUNCT', 'ADV', 'PROPN', 'VERB',\n",
       "       'ADP', 'DET', 'NOUN', 'CONJ', 'VERB', 'ADP', 'PUNCT', 'PRON',\n",
       "       'AUX', 'VERB', 'NOUN', 'CONJ', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP',\n",
       "       'DET', 'NOUN', 'PUNCT', 'ADV', 'DET', 'NOUN', 'CONJ', 'DET',\n",
       "       'NOUN', 'VERB', 'DET', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'DET',\n",
       "       'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET',\n",
       "       'NOUN', 'PUNCT', 'DET', 'NOUN', 'AUX', 'VERB', 'DET', 'VERB',\n",
       "       'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', 'PUNCT', 'ADP', 'ADJ',\n",
       "       'NOUN', 'VERB', 'ADP', 'PRON', 'PUNCT', 'ADV', 'DET', 'NOUN',\n",
       "       'VERB', 'PART', 'ADJ', 'PUNCT', 'ADP', 'DET', 'NOUN', 'AUX',\n",
       "       'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'SCONJ',\n",
       "       'PRON', 'VERB', 'DET', 'ADJ', 'ADJ', 'NOUN', 'PART', 'AUX', 'VERB',\n",
       "       'ADV', 'PUNCT', 'ADV', 'DET', 'NOUN', 'AUX', 'AUX', 'VERB',\n",
       "       'PUNCT', 'CONJ', 'DET', 'NOUN', 'PUNCT', 'DET', 'NOUN', 'CONJ',\n",
       "       'DET', 'NOUN', 'VERB', 'PRON', 'ADV', 'PUNCT', 'CONJ', 'ADV',\n",
       "       'DET', 'NOUN', 'VERB', 'ADV', 'ADJ', 'CONJ', 'VERB', 'ADP', 'NOUN',\n",
       "       'ADJ', 'PUNCT', 'ADV', 'NOUN', 'PROPN', 'VERB', 'ADV', 'PART',\n",
       "       'VERB', 'PRON', 'VERB', 'DET', 'ADJ', 'PUNCT', 'ADJ', 'NOUN',\n",
       "       'PUNCT', 'DET', 'NOUN', 'CONJ', 'NOUN', 'AUX', 'VERB', 'PRON',\n",
       "       'PUNCT', 'ADV', 'PUNCT', 'PRON', 'AUX', 'VERB', 'DET', 'NOUN',\n",
       "       'ADP', 'PRON', 'NOUN', 'CONJ', 'VERB', 'PRON', 'DET', 'ADJ',\n",
       "       'NOUN', 'PUNCT', 'PRON', 'AUX', 'VERB', 'DET', 'NOUN', 'ADP',\n",
       "       'PRON', 'NOUN', 'CONJ', 'NOUN', 'PUNCT', 'CONJ', 'PRON', 'VERB',\n",
       "       'ADJ', 'ADV', 'PUNCT', 'PRON', 'VERB', 'ADJ', 'CONJ', 'PROPN',\n",
       "       'PUNCT', 'CONJ', 'ADV', 'VERB', 'ADV', 'PUNCT', 'SCONJ', 'PROPN',\n",
       "       'PUNCT', 'PRON', 'VERB', 'DET', 'NOUN', 'PUNCT', 'ADV', 'VERB',\n",
       "       'ADP', 'PRON', 'PUNCT', 'NOUN', 'PROPN', 'AUX', 'AUX', 'ADV',\n",
       "       'ADJ', 'ADP', 'DET', 'NUM', 'NOUN', 'SCONJ', 'PRON', 'AUX', 'VERB',\n",
       "       'CONJ', 'VERB', 'PRON', 'NOUN', 'ADP', 'PRON', 'NOUN', 'SCONJ',\n",
       "       'NUM', 'NOUN', 'NOUN', 'VERB', 'PRON', 'NOUN', 'PUNCT', 'CONJ',\n",
       "       'PRON', 'ADV', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'ADP', 'VERB',\n",
       "       'SCONJ', 'PRON', 'AUX', 'VERB', 'NOUN', 'PART', 'VERB', 'ADP',\n",
       "       'PUNCT'], dtype='<U5')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = Text(text)\n",
    "\n",
    "tag_list = []\n",
    "for token in tokens.pos_tags:\n",
    "        tag_list.append(token[1])\n",
    "        \n",
    "tag_arr = np.array(tag_list)\n",
    "tag_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pragraph_split_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2c53728060b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmor_paragrah_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mparagraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpragraph_split_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtemp_mor_paragrah_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pragraph_split_list' is not defined"
     ]
    }
   ],
   "source": [
    "mor_sentence_list = [ ]\n",
    "mor_paragrah_list = [ ]\n",
    "\n",
    "for paragraph in pragraph_split_list:\n",
    "    \n",
    "    temp_mor_paragrah_list = [ ]\n",
    "    for sentence in paragraph:\n",
    "        tokens = Text(sentence)\n",
    "        \n",
    "        temp_mor_sentence_list = [ ]\n",
    "        for token in tokens.pos_tags:\n",
    "            temp_mor_sentence_list.append(token[1])\n",
    "        \n",
    "        mor_sentence_list = temp_mor_sentence_list\n",
    "#         print(mor_sentence_list, len(mor_sentence_list))\n",
    "            \n",
    "        temp_mor_paragrah_list.append(mor_sentence_list)\n",
    "        \n",
    "    mor_paragrah_list.append(temp_mor_paragrah_list)\n",
    "    \n",
    "    \n",
    "print(mor_paragrah_list)\n",
    "    \n",
    "# arr_morpheme = np.array(mor_paragrah_list)\n",
    "\n",
    "# np.set_printoptions(threshold=np.inf)     #printを省略しない\n",
    "\n",
    "# print(arr_morpheme)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "# tokens = Text(contents)\n",
    "\n",
    "# morpheme_list = [ ]\n",
    "\n",
    "# for token in tokens.pos_tags:\n",
    "#     morpheme_list.append(token[1])\n",
    "\n",
    "# print(morpheme_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2 = np.array([[1,2,3],[4,5]])\n",
    "print(vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
